{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenneth/Public/projects/python/ai/ConvolutionLab/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Step 1: Load the Test Dataset\n",
    "- Ensure the dataset contains the same features used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Volume     Open     High      Low    Close      AHMA  Leavitt_Projection  \\\n",
      "0   83882  1.07566  1.07650  1.07112  1.07298  1.071736            1.066661   \n",
      "1   88884  1.07298  1.07523  1.06319  1.06440  1.069301            1.066886   \n",
      "2   75731  1.06440  1.06878  1.06333  1.06592  1.067177            1.066743   \n",
      "3   56799  1.06592  1.06989  1.06548  1.06919  1.066696            1.066478   \n",
      "4   60101  1.06919  1.07180  1.06752  1.06791  1.066469            1.066136   \n",
      "\n",
      "   Leavitt_Convolution  LC_Slope  LC_Intercept  ...  Returns_T-10  \\\n",
      "0             1.066535  0.000123      1.066167  ...      0.004100   \n",
      "1             1.067539  0.000546      1.065900  ...     -0.007324   \n",
      "2             1.066845  0.000041      1.066722  ...     -0.006290   \n",
      "3             1.066294 -0.000204      1.066906  ...      0.001986   \n",
      "4             1.065846 -0.000303      1.066756  ...     -0.006937   \n",
      "\n",
      "   Momentum_T-10  Returns_T-21  Momentum_T-21  Hour  Day_Of_Week  Month  Year  \\\n",
      "0      -0.006591     -0.000257      -0.002235    21            1      9  2023   \n",
      "1      -0.000673     -0.002311      -0.005685    21            2      9  2023   \n",
      "2       0.007718     -0.000634       0.002062    21            3      9  2023   \n",
      "3       0.001082      0.000037       0.003031    21            6      9  2023   \n",
      "4       0.005740      0.002115      -0.003313    21            0      9  2023   \n",
      "\n",
      "        ATR  Movement_Class  \n",
      "0  0.006449               0  \n",
      "1  0.007194               0  \n",
      "2  0.006962               1  \n",
      "3  0.006622               2  \n",
      "4  0.006309               1  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset\n",
    "test_data_path = \"../../artifacts/data/processed/test.csv\"  # Adjust path as needed\n",
    "df_test = pd.read_csv(test_data_path)\n",
    "\n",
    "# Display sample data\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Now, we have the test dataset loaded with Date as the index.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Step 2: Extract the Correct Features\n",
    "- To ensure model compatibility, extract only the features used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Features:\n",
      "    Volume     Open     High      Low    Close      AHMA  Leavitt_Projection  \\\n",
      "0   83882  1.07566  1.07650  1.07112  1.07298  1.071736            1.066661   \n",
      "1   88884  1.07298  1.07523  1.06319  1.06440  1.069301            1.066886   \n",
      "2   75731  1.06440  1.06878  1.06333  1.06592  1.067177            1.066743   \n",
      "3   56799  1.06592  1.06989  1.06548  1.06919  1.066696            1.066478   \n",
      "4   60101  1.06919  1.07180  1.06752  1.06791  1.066469            1.066136   \n",
      "\n",
      "   Leavitt_Convolution  LC_Slope  LC_Intercept  ...  Momentum_T-5  \\\n",
      "0             1.066535  0.000123      1.066167  ...     -0.003004   \n",
      "1             1.067539  0.000546      1.065900  ...     -0.005079   \n",
      "2             1.066845  0.000041      1.066722  ...      0.001120   \n",
      "3             1.066294 -0.000204      1.066906  ...     -0.001718   \n",
      "4             1.065846 -0.000303      1.066756  ...     -0.001774   \n",
      "\n",
      "   Returns_T-10  Momentum_T-10  Returns_T-21  Momentum_T-21  Hour  \\\n",
      "0      0.004100      -0.006591     -0.000257      -0.002235    21   \n",
      "1     -0.007324      -0.000673     -0.002311      -0.005685    21   \n",
      "2     -0.006290       0.007718     -0.000634       0.002062    21   \n",
      "3      0.001986       0.001082      0.000037       0.003031    21   \n",
      "4     -0.006937       0.005740      0.002115      -0.003313    21   \n",
      "\n",
      "   Day_Of_Week  Month  Year       ATR  \n",
      "0            1      9  2023  0.006449  \n",
      "1            2      9  2023  0.007194  \n",
      "2            3      9  2023  0.006962  \n",
      "3            6      9  2023  0.006622  \n",
      "4            0      9  2023  0.006309  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract feature columns (remove target columns)\n",
    "target_column = \"Movement_Class\"  # Adjust if needed\n",
    "original_features = [col for col in df_test.columns if col != target_column]\n",
    "\n",
    "# Select matching features in the test set\n",
    "X_test = df_test[original_features].dropna()\n",
    "\n",
    "# Display extracted features\n",
    "print(\"Extracted Features:\\n\", X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Ensures test features match training features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üîπ Step 3: Handle Missing or Unmatched Columns\n",
    "- If columns are missing, handle them gracefully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Volume', 'Open', 'High', 'Low', 'Close', 'AHMA', 'Leavitt_Projection', 'Leavitt_Convolution', 'LC_Slope', 'LC_Intercept', 'LC_Acceleration', 'Convolution_Probability', 'Returns', 'Returns_T-1', 'Momentum_T-1', 'Returns_T-2', 'Momentum_T-2', 'Returns_T-5', 'Momentum_T-5', 'Returns_T-10', 'Momentum_T-10', 'Returns_T-21', 'Momentum_T-21', 'Hour', 'Day_Of_Week', 'Month', 'Year', 'ATR']\n"
     ]
    }
   ],
   "source": [
    "print(original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((364, 28),\n",
       " Index(['Volume', 'Open', 'High', 'Low', 'Close', 'AHMA', 'Leavitt_Projection',\n",
       "        'Leavitt_Convolution', 'LC_Slope', 'LC_Intercept', 'LC_Acceleration',\n",
       "        'Convolution_Probability', 'Returns', 'Returns_T-1', 'Momentum_T-1',\n",
       "        'Returns_T-2', 'Momentum_T-2', 'Returns_T-5', 'Momentum_T-5',\n",
       "        'Returns_T-10', 'Momentum_T-10', 'Returns_T-21', 'Momentum_T-21',\n",
       "        'Hour', 'Day_Of_Week', 'Month', 'Year', 'ATR'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure test set has all required columns\n",
    "missing_cols = [col for col in original_features if col not in df_test.columns]\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"‚ö†Ô∏è Warning: Missing Columns in Test Data: {missing_cols}\")\n",
    "\n",
    "    # Option 1: Fill with Zeros (if reasonable)\n",
    "    for col in missing_cols:\n",
    "        df_test[col] = 0\n",
    "\n",
    "    # Option 2: Drop Columns from Feature List (only if necessary)\n",
    "    original_features = [col for col in original_features if col in df_test.columns]\n",
    "\n",
    "# Extract final feature set\n",
    "X_test = df_test[original_features]\n",
    "X_test.shape, X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model (XGBoost or CatBoost)\n",
    "#model_path = \"../../artifacts/models/cat_boost_model.pkl\"  # Adjust based on best model\n",
    "model_path = \"../../artifacts/models/model.pkl\"  # Adjust based on best model\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Handles missing features safely without breaking the model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Step 4: Normalize or Scale If Needed\n",
    "- If you applied scaling (StandardScaler, MinMaxScaler) during training, apply the same here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Volume        Open        High         Low       Close  \\\n",
      "count     364.000000  364.000000  364.000000  364.000000  364.000000   \n",
      "mean    98902.310440    1.077004    1.080182    1.073594    1.076900   \n",
      "std     43781.512779    0.020741    0.020492    0.021172    0.020843   \n",
      "min     27385.000000    1.024340    1.025010    1.017790    1.024340   \n",
      "25%     72227.250000    1.063748    1.067155    1.059958    1.062455   \n",
      "50%     87707.000000    1.080850    1.083850    1.077900    1.080850   \n",
      "75%    113760.250000    1.089870    1.093125    1.087330    1.089870   \n",
      "max    398838.000000    1.119280    1.121420    1.115020    1.119280   \n",
      "\n",
      "             AHMA  Leavitt_Projection  Leavitt_Convolution    LC_Slope  \\\n",
      "count  364.000000          364.000000           364.000000  364.000000   \n",
      "mean     1.076880            1.076776             1.076689   -0.000087   \n",
      "std      0.021086            0.022037             0.022569    0.002399   \n",
      "min      1.025912            1.024600             1.024073   -0.007657   \n",
      "25%      1.062450            1.060940             1.060908   -0.001585   \n",
      "50%      1.080831            1.079945             1.079637   -0.000104   \n",
      "75%      1.090548            1.090576             1.090713    0.001554   \n",
      "max      1.119660            1.124341             1.126670    0.006040   \n",
      "\n",
      "       LC_Intercept  ...  Momentum_T-5  Returns_T-10  Momentum_T-10  \\\n",
      "count    364.000000  ...    364.000000    364.000000   3.640000e+02   \n",
      "mean       1.076949  ...     -0.000005     -0.000090  -2.706718e-07   \n",
      "std        0.021869  ...      0.005718      0.004052   5.722108e-03   \n",
      "min        1.024216  ...     -0.021894     -0.018363  -1.682560e-02   \n",
      "25%        1.061672  ...     -0.003336     -0.002552  -3.186787e-03   \n",
      "50%        1.080011  ...      0.000070     -0.000032  -1.617036e-05   \n",
      "75%        1.090461  ...      0.003394      0.002476   3.305506e-03   \n",
      "max        1.124652  ...      0.018456      0.016805   2.063900e-02   \n",
      "\n",
      "       Returns_T-21  Momentum_T-21        Hour  Day_Of_Week       Month  \\\n",
      "count    364.000000     364.000000  364.000000   364.000000  364.000000   \n",
      "mean      -0.000150       0.000059   21.428571     2.384615    6.950549   \n",
      "std        0.003964       0.005631    0.495553     2.046400    3.769937   \n",
      "min       -0.018363      -0.018900   21.000000     0.000000    1.000000   \n",
      "25%       -0.002552      -0.003353   21.000000     1.000000    3.000000   \n",
      "50%       -0.000055       0.000221   21.000000     2.000000    8.000000   \n",
      "75%        0.002467       0.003284   22.000000     3.000000   10.000000   \n",
      "max        0.016805       0.027661   22.000000     6.000000   12.000000   \n",
      "\n",
      "              Year         ATR  \n",
      "count   364.000000  364.000000  \n",
      "mean   2023.862637    0.006556  \n",
      "std       0.517282    0.001313  \n",
      "min    2023.000000    0.004043  \n",
      "25%    2024.000000    0.005487  \n",
      "50%    2024.000000    0.006442  \n",
      "75%    2024.000000    0.007403  \n",
      "max    2025.000000    0.010471  \n",
      "\n",
      "[8 rows x 28 columns]\n",
      "<class 'numpy.ndarray'>\n",
      "(364, 47)\n"
     ]
    }
   ],
   "source": [
    "# Load the saved scaler\n",
    "scaler_path = \"../../artifacts/preprocessor.pkl\"  # Adjust path\n",
    "scaler = joblib.load(scaler_path)\n",
    "\n",
    "print(X_test.describe())\n",
    "\n",
    "# Transform test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(type(X_test_scaled))\n",
    "# Check the shape\n",
    "print(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num_pipeline__Leavitt_Projection' 'num_pipeline__Leavitt_Convolution'\n",
      " 'num_pipeline__LC_Slope' 'num_pipeline__LC_Acceleration'\n",
      " 'num_pipeline__Convolution_Probability' 'num_pipeline__Momentum_T-1'\n",
      " 'num_pipeline__Momentum_T-2' 'num_pipeline__Momentum_T-5'\n",
      " 'num_pipeline__Momentum_T-10' 'num_pipeline__Momentum_T-21'\n",
      " 'num_pipeline__Returns_T-1' 'num_pipeline__Returns_T-2'\n",
      " 'num_pipeline__Returns_T-5' 'num_pipeline__Returns_T-10'\n",
      " 'num_pipeline__Returns_T-21' 'num_pipeline__AHMA' 'num_pipeline__ATR'\n",
      " 'num_pipeline__Volume' 'num_pipeline__Open' 'num_pipeline__High'\n",
      " 'num_pipeline__Low' 'num_pipeline__Close' 'cat_pipeline__Day_Of_Week_0'\n",
      " 'cat_pipeline__Day_Of_Week_1' 'cat_pipeline__Day_Of_Week_2'\n",
      " 'cat_pipeline__Day_Of_Week_3' 'cat_pipeline__Day_Of_Week_4'\n",
      " 'cat_pipeline__Day_Of_Week_6' 'cat_pipeline__Month_1'\n",
      " 'cat_pipeline__Month_2' 'cat_pipeline__Month_3' 'cat_pipeline__Month_4'\n",
      " 'cat_pipeline__Month_5' 'cat_pipeline__Month_6' 'cat_pipeline__Month_7'\n",
      " 'cat_pipeline__Month_8' 'cat_pipeline__Month_9' 'cat_pipeline__Month_10'\n",
      " 'cat_pipeline__Month_11' 'cat_pipeline__Month_12'\n",
      " 'cat_pipeline__Year_2018' 'cat_pipeline__Year_2019'\n",
      " 'cat_pipeline__Year_2020' 'cat_pipeline__Year_2021'\n",
      " 'cat_pipeline__Year_2022' 'cat_pipeline__Hour_21' 'cat_pipeline__Hour_22']\n"
     ]
    }
   ],
   "source": [
    "# Assuming the preprocessor has a method to get feature names\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Extract feature names (for ColumnTransformer pipelines)\n",
    "if isinstance(scaler, ColumnTransformer):\n",
    "    feature_names = scaler.get_feature_names_out()\n",
    "else:\n",
    "    feature_names = X_test.columns  # Fallback to original names\n",
    "\n",
    "# Print new feature names\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_pipeline__Leavitt_Projection  num_pipeline__Leavitt_Convolution  \\\n",
      "0                         -1.608249                          -1.594792   \n",
      "1                         -1.603641                          -1.574405   \n",
      "2                         -1.606567                          -1.588491   \n",
      "3                         -1.611984                          -1.599676   \n",
      "4                         -1.618977                          -1.608786   \n",
      "\n",
      "   num_pipeline__LC_Slope  num_pipeline__LC_Acceleration  \\\n",
      "0                0.100374                       1.532692   \n",
      "1                0.235184                       0.329090   \n",
      "2                0.074449                      -0.387264   \n",
      "3               -0.003514                      -0.186636   \n",
      "4               -0.035146                      -0.074339   \n",
      "\n",
      "   num_pipeline__Convolution_Probability  num_pipeline__Momentum_T-1  \\\n",
      "0                               0.043438                   -0.511838   \n",
      "1                               0.118061                   -0.918097   \n",
      "2                               0.025859                    1.570994   \n",
      "3                              -0.019794                    0.273092   \n",
      "4                              -0.041086                   -0.711361   \n",
      "\n",
      "   num_pipeline__Momentum_T-2  num_pipeline__Momentum_T-5  \\\n",
      "0                   -1.236366                   -0.497703   \n",
      "1                   -1.456598                   -0.841219   \n",
      "2                    0.665908                    0.185307   \n",
      "3                    1.879788                   -0.284577   \n",
      "4                   -0.446042                   -0.293895   \n",
      "\n",
      "   num_pipeline__Momentum_T-10  num_pipeline__Momentum_T-21  ...  \\\n",
      "0                    -1.090962                    -0.365451  ...   \n",
      "1                    -0.110729                    -0.941589  ...   \n",
      "2                     1.278879                     0.352008  ...   \n",
      "3                     0.179841                     0.513749  ...   \n",
      "4                     0.951384                    -0.545402  ...   \n",
      "\n",
      "   cat_pipeline__Month_10  cat_pipeline__Month_11  cat_pipeline__Month_12  \\\n",
      "0                     0.0                     0.0                     0.0   \n",
      "1                     0.0                     0.0                     0.0   \n",
      "2                     0.0                     0.0                     0.0   \n",
      "3                     0.0                     0.0                     0.0   \n",
      "4                     0.0                     0.0                     0.0   \n",
      "\n",
      "   cat_pipeline__Year_2018  cat_pipeline__Year_2019  cat_pipeline__Year_2020  \\\n",
      "0                      0.0                      0.0                      0.0   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   cat_pipeline__Year_2021  cat_pipeline__Year_2022  cat_pipeline__Hour_21  \\\n",
      "0                      0.0                      0.0               2.125454   \n",
      "1                      0.0                      0.0               2.125454   \n",
      "2                      0.0                      0.0               2.125454   \n",
      "3                      0.0                      0.0               2.125454   \n",
      "4                      0.0                      0.0               2.125454   \n",
      "\n",
      "   cat_pipeline__Hour_22  \n",
      "0                    0.0  \n",
      "1                    0.0  \n",
      "2                    0.0  \n",
      "3                    0.0  \n",
      "4                    0.0  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert scaled NumPy array back to DataFrame\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
    "\n",
    "# # Verify DataFrame structure\n",
    "print(X_test_scaled_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Ensures feature scaling is consistent for testing.\n",
    "\n",
    "---\n",
    "\n",
    "Step 2: Predict Predicted_Direction\n",
    "We assume the model predicts residuals that correct Leavitt_Convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SHAP explainer\n",
    "# explainer = shap.Explainer(model, X_test_scaled_df)\n",
    "\n",
    "# # Compute SHAP values\n",
    "# shap_values = explainer(X_test_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap.summary_plot(shap_values, X_test_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap.summary_plot(shap_values, X_test_scaled_df, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_test.shape, X_test_scaled_df.shape, shap_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"cat_pipeline__Month_6\" in X_test_scaled_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SHAP values for dependence plot\n",
    "#shap_values_array = shap_values.values\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
