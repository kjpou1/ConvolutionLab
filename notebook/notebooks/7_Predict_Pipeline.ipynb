{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Set the base directory so we can find things\n",
    "\n",
    "- All is loaded from the \"../../artifacts\"\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../artifacts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"BASE_DIR\"] = \"../../artifacts\"\n",
    "\n",
    "# Verify it's set\n",
    "print(os.environ.get(\"BASE_DIR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_ohlcv(record):\n",
    "    \"\"\"\n",
    "    Validates whether the input record follows the required OHLCV format.\n",
    "    Ensures correct data structure, types, and valid `Date` formats.\n",
    "\n",
    "    Args:\n",
    "        record (list or dict): A single OHLCV record.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the record is valid, otherwise raises an error.\n",
    "    \"\"\"\n",
    "    expected_keys = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "\n",
    "    if isinstance(record, dict):\n",
    "        # Ensure all required keys exist\n",
    "        if not all(key in record for key in expected_keys):\n",
    "            raise ValueError(\n",
    "                f\"Invalid OHLCV record: Missing required keys. Expected: {expected_keys}. Received: {list(record.keys())}\"\n",
    "            )\n",
    "\n",
    "        # Validate `Date` format\n",
    "        try:\n",
    "            pd.to_datetime(record[\"Date\"])  # Converts to datetime to check validity\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Invalid `Date` format: {record['Date']}\")\n",
    "\n",
    "        # Ensure numerical fields are valid\n",
    "        if not all(\n",
    "            isinstance(record[key], (int, float)) for key in expected_keys[1:]\n",
    "        ):  # Exclude `Date`\n",
    "            raise ValueError(\n",
    "                f\"Invalid OHLCV record: Values must be int/float for OHLCV fields. Received: {record}\"\n",
    "            )\n",
    "\n",
    "    elif isinstance(record, list):\n",
    "        # Ensure list has exactly 6 elements (Date + OHLCV)\n",
    "        if len(record) != 6:\n",
    "            raise ValueError(\n",
    "                f\"Invalid OHLCV record: Expected 6 elements (Date + OHLCV), got {len(record)}\"\n",
    "            )\n",
    "\n",
    "        # Validate `Date` format\n",
    "        try:\n",
    "            pd.to_datetime(record[0])  # Converts to datetime to check validity\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Invalid `Date` format: {record[0]}\")\n",
    "\n",
    "        # Ensure OHLCV values are numeric\n",
    "        if not all(isinstance(value, (int, float)) for value in record[1:]):\n",
    "            raise ValueError(\n",
    "                f\"Invalid OHLCV record: Values must be int/float for OHLCV fields. Received: {record}\"\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        raise TypeError(\"Invalid input type. Record must be a dictionary or list.\")\n",
    "\n",
    "    return True  # If no errors, return True (valid record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError caught: Invalid OHLCV record: Missing required keys. Expected: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']. Received: ['Open', 'High', 'Low']\n",
      "ValueError caught: Invalid `Date` format: Invalid Date\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "valid_dict = {\n",
    "    \"Date\": \"2025-02-06 22:00:00-05:00\",  # Valid timezone-aware format\n",
    "    \"Open\": 1.03612,\n",
    "    \"High\": 1.03858,\n",
    "    \"Low\": 1.0354,\n",
    "    \"Close\": 1.03737,\n",
    "    \"Volume\": 55878,\n",
    "}\n",
    "valid_list = [\"2025-02-06 22:00:00\", 1.03612, 1.03858, 1.0354, 1.03737, 55878]\n",
    "invalid_dict = {\"Open\": 1.03612, \"High\": 1.03858, \"Low\": 1.0354}  # Missing keys\n",
    "invalid_list = [\n",
    "    \"Invalid Date\",\n",
    "    1.03612,\n",
    "    1.03858,\n",
    "    1.0354,\n",
    "    1.03737,\n",
    "    55878,\n",
    "]  # Invalid date\n",
    "\n",
    "# Assertions for valid cases\n",
    "assert validate_ohlcv(valid_dict) == True  # ‚úÖ Should pass\n",
    "assert validate_ohlcv(valid_list) == True  # ‚úÖ Should pass\n",
    "\n",
    "# Assertions for invalid cases (expected to fail)\n",
    "try:\n",
    "    assert validate_ohlcv(invalid_dict) == True  # ‚ùå Should raise ValueError\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError caught: {e}\")\n",
    "\n",
    "try:\n",
    "    assert validate_ohlcv(invalid_list) == True  # ‚ùå Should raise ValueError\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError caught: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_ohlcv_batch(records):\n",
    "    \"\"\"\n",
    "    Validates a batch of OHLCV records using assertions.\n",
    "\n",
    "    Args:\n",
    "        records (list): A list of OHLCV records (each record is a list or dict).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of booleans indicating validity of each record.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i, record in enumerate(records):\n",
    "        try:\n",
    "            assert validate_ohlcv(record) == True  # Assert validity\n",
    "            results.append(True)  # Valid record\n",
    "        except ValueError as e:\n",
    "            print(f\"AssertionError: Record {i} failed validation: {e}\")\n",
    "            results.append(False)  # Invalid record\n",
    "\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssertionError: Record 0 failed validation: Invalid `Date` format: Invalid Date\n",
      "AssertionError: Record 1 failed validation: Invalid OHLCV record: Expected 6 elements (Date + OHLCV), got 4\n",
      "AssertionError: Record 2 failed validation: Invalid OHLCV record: Missing required keys. Expected: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']. Received: ['Date', 'Open', 'High', 'Low']\n",
      "AssertionError caught: \n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "valid_records = [\n",
    "    [\n",
    "        \"2025-02-06 22:00:00\",\n",
    "        1.03612,\n",
    "        1.03858,\n",
    "        1.0354,\n",
    "        1.03737,\n",
    "        55878,\n",
    "    ],  # Standard datetime format\n",
    "    [\"2025-02-07\", 1.03812, 1.03758, 1.0384, 1.03537, 69878],  # Date-only format\n",
    "    {\n",
    "        \"Date\": \"2025-02-06 22:00:00-05:00\",\n",
    "        \"Open\": 1.03612,\n",
    "        \"High\": 1.03858,\n",
    "        \"Low\": 1.0354,\n",
    "        \"Close\": 1.03737,\n",
    "        \"Volume\": 55878,\n",
    "    },  # ISO 8601 format\n",
    "    [\n",
    "        \"2025-02-06T22:00:00-05:00\",\n",
    "        1.03812,\n",
    "        1.03758,\n",
    "        1.0384,\n",
    "        1.03537,\n",
    "        69878,\n",
    "    ],  #\n",
    "    [\n",
    "        \"2025-02-06T22:00:00\",\n",
    "        1.03812,\n",
    "        1.03758,\n",
    "        1.0384,\n",
    "        1.03537,\n",
    "        69878,\n",
    "    ],  #\n",
    "]\n",
    "\n",
    "invalid_records = [\n",
    "    [\"Invalid Date\", 1.03612, 1.03858, 1.0354, 1.03737, 55878],  # Invalid date format\n",
    "    [1.03612, 1.03858, 1.0354, 1.03737],  # Missing volume\n",
    "    {\n",
    "        \"Date\": \"2025-02-06 22:00:00-05:00\",\n",
    "        \"Open\": 1.03612,\n",
    "        \"High\": 1.03858,\n",
    "        \"Low\": 1.0354,\n",
    "    },  # Missing Close & Volume\n",
    "]\n",
    "\n",
    "# Assertions for batch validation\n",
    "assert validate_ohlcv_batch(valid_records) == [True, True, True, True, True]  # ‚úÖ Should pass\n",
    "\n",
    "try:\n",
    "    assert validate_ohlcv_batch(invalid_records) == [True, True, True]  # ‚ùå Should fail\n",
    "except AssertionError as e:\n",
    "    print(f\"AssertionError caught: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Step 1: Load the Test Dataset\n",
    "- Ensure the dataset contains the same features used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                       time  volume    mid_o    mid_h   mid_l  \\\n",
      "1846        1846  2025-02-11 22:00:00-05:00   55878  1.03612  1.03858  1.0354   \n",
      "\n",
      "        mid_c    bid_o   bid_h    bid_l    bid_c    ask_o    ask_h    ask_l  \\\n",
      "1846  1.03737  1.03604  1.0385  1.03532  1.03729  1.03621  1.03865  1.03548   \n",
      "\n",
      "        ask_c  \n",
      "1846  1.03745  \n",
      "(1847, 15)\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset\n",
    "test_data_path = \"../data/Predict_EUR_USD_D.csv\"  # Adjust path as needed\n",
    "df_analyze = pd.read_csv(test_data_path)\n",
    "\n",
    "# Display sample data\n",
    "print(df_analyze.tail(1))\n",
    "print(df_analyze.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Step 2: Extract lookback\n",
    "\n",
    "- Now, grab the data we are interest in for our lookback analysis\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                      time  volume    mid_o    mid_h   mid_l  \\\n",
      "1846        1846 2025-02-11 22:00:00-05:00   55878  1.03612  1.03858  1.0354   \n",
      "\n",
      "        mid_c    bid_o   bid_h    bid_l    bid_c    ask_o    ask_h    ask_l  \\\n",
      "1846  1.03737  1.03604  1.0385  1.03532  1.03729  1.03621  1.03865  1.03548   \n",
      "\n",
      "        ask_c  \n",
      "1846  1.03745  \n",
      "(100, 15)\n"
     ]
    }
   ],
   "source": [
    "lookback = 100\n",
    "\n",
    "# Select the last lookback number of rows from the dataset\n",
    "df_lookback = df_analyze.tail(lookback).copy()\n",
    "\n",
    "# Convert the 'time' column to datetime format for proper analysis\n",
    "df_lookback[\"time\"] = pd.to_datetime(df_lookback[\"time\"])\n",
    "\n",
    "print(df_lookback.tail(1))\n",
    "print(df_lookback.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Step 2: Reformat into DOHLCV\n",
    "- Manipulate the dataset into our alternative formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_to_dohlcv(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Converts a dataset from mid_* format to DOHLCV format.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Raw dataset with `time`, `volume`, `mid_*`, `bid_*`, `ask_*`.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Reformatted dataset in `Date, Open, High, Low, Close, Volume` format.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert 'time' to 'Date' and ensure correct datetime format\n",
    "        if \"time\" in df.columns:\n",
    "            df = df.rename(columns={\"time\": \"Date\"})\n",
    "            df[\"Date\"] = pd.to_datetime(\n",
    "                df[\"Date\"]\n",
    "            )  # Ensures proper datetime conversion\n",
    "\n",
    "        # Drop unnecessary bid/ask price columns\n",
    "        columns_to_drop = [\n",
    "            \"bid_o\",\n",
    "            \"bid_h\",\n",
    "            \"bid_l\",\n",
    "            \"bid_c\",\n",
    "            \"ask_o\",\n",
    "            \"ask_h\",\n",
    "            \"ask_l\",\n",
    "            \"ask_c\",\n",
    "        ]\n",
    "        df.drop(\n",
    "            columns=[col for col in columns_to_drop if col in df.columns],\n",
    "            errors=\"ignore\",\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        # Rename mid-price columns to standard OHLCV format\n",
    "        rename_mapping = {\n",
    "            \"mid_o\": \"Open\",\n",
    "            \"mid_h\": \"High\",\n",
    "            \"mid_l\": \"Low\",\n",
    "            \"mid_c\": \"Close\",\n",
    "            \"volume\": \"Volume\",\n",
    "        }\n",
    "        df = df.rename(columns=rename_mapping)\n",
    "\n",
    "        # Ensure correct column order for DOHLCV\n",
    "        dohlcv_columns = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "        df = df[dohlcv_columns]\n",
    "\n",
    "        print(\"Dataset successfully reformatted to DOHLCV format.\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during reformatting: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully reformatted to DOHLCV format.\n"
     ]
    }
   ],
   "source": [
    "df_dohlcv = reformat_to_dohlcv(df_lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Date     Open     High     Low    Close  Volume\n",
      "1846 2025-02-11 22:00:00-05:00  1.03612  1.03858  1.0354  1.03737   55878\n",
      "(100, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df_dohlcv.tail(1))\n",
    "print(df_dohlcv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ File saved successfully.\n"
     ]
    }
   ],
   "source": [
    "df_dohlcv.to_csv(\"../data/lookback_dohlcv.csv\", index=False)\n",
    "print(\"‚úÖ File saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Step 3: Run it through data ingestion \n",
    "\n",
    "- Compute all the features \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2025-02-15 04:29:23,495 ] INFO [src.services.data_ingestion_service:67] - Dropped bid and ask price columns.\n",
      "[ 2025-02-15 04:29:23,495 ] INFO [src.services.data_ingestion_service:80] - Renamed mid-price columns to OHLC format.\n",
      "[ 2025-02-15 04:29:23,496 ] INFO [src.services.data_ingestion_service:93] - Set index to Date with unique timestamps.\n",
      "[ 2025-02-15 04:29:23,497 ] INFO [src.services.data_ingestion_service:95] - Processing leavitt data.\n",
      "[ 2025-02-15 04:29:23,507 ] INFO [src.services.data_ingestion_service:97] - Finished leavitt data.\n",
      "[ 2025-02-15 04:29:23,507 ] INFO [src.services.data_ingestion_service:99] - Processing indicators.\n",
      "[ 2025-02-15 04:29:23,510 ] INFO [src.services.data_ingestion_service:101] - Finished indicators.\n",
      "[ 2025-02-15 04:29:23,510 ] INFO [src.services.data_ingestion_service:103] - Processing target.\n",
      "[ 2025-02-15 04:29:23,511 ] INFO [src.services.data_ingestion_service:105] - Finished target.\n",
      "[ 2025-02-15 04:29:23,513 ] INFO [src.services.data_ingestion_service:112] - Dropped NaNs from all columns except Target_T+* fields.\n",
      "[ 2025-02-15 04:29:23,513 ] INFO [src.services.data_ingestion_service:117] - [Data Preprocessing] Input Data Shape: (78, 29)\n",
      "[ 2025-02-15 04:29:23,514 ] INFO [src.services.data_ingestion_service:118] - [Data Preprocessing] Checking for NaNs: 0 NaNs found\n"
     ]
    }
   ],
   "source": [
    "from src.services.data_ingestion_service import DataIngestionService\n",
    "\n",
    "ingestion_service = DataIngestionService()\n",
    "# Apply preprocessing (renaming, dropping unnecessary columns)\n",
    "df_cleaned = ingestion_service.preprocess_data(df_dohlcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 29)\n",
      "            Open       High        Low      Close         Volume       AHMA  \\\n",
      "count  78.000000  78.000000  78.000000  78.000000      78.000000  78.000000   \n",
      "mean    1.050034   1.053723   1.045359   1.049511  158979.858974   1.049304   \n",
      "std     0.017334   0.017146   0.017282   0.017086   48031.345766   0.016844   \n",
      "min     1.024340   1.025010   1.017790   1.024340   55878.000000   1.025912   \n",
      "25%     1.037985   1.042588   1.034203   1.037497  132557.750000   1.037979   \n",
      "50%     1.048200   1.052290   1.041620   1.047060  160770.500000   1.046549   \n",
      "75%     1.056715   1.059658   1.052647   1.056607  178745.500000   1.053758   \n",
      "max     1.092970   1.093740   1.087260   1.092970  398838.000000   1.088000   \n",
      "\n",
      "       Leavitt_Projection  Leavitt_Convolution   LC_Slope  LC_Intercept  ...  \\\n",
      "count           78.000000            78.000000  78.000000     78.000000  ...   \n",
      "mean             1.048633             1.048046  -0.000582      1.049792  ...   \n",
      "std              0.017553             0.017992   0.002610      0.018001  ...   \n",
      "min              1.024600             1.024073  -0.007657      1.024216  ...   \n",
      "25%              1.035271             1.033832  -0.001739      1.036387  ...   \n",
      "50%              1.045268             1.044582  -0.000582      1.045447  ...   \n",
      "75%              1.055039             1.056008   0.001053      1.055633  ...   \n",
      "max              1.088157             1.090368   0.004838      1.088485  ...   \n",
      "\n",
      "       Returns_T-10  Momentum_T-10  Returns_T-21  Momentum_T-21       Hour  \\\n",
      "count     78.000000      78.000000     78.000000      78.000000  78.000000   \n",
      "mean      -0.000612       0.000129     -0.001029       0.000547  21.910256   \n",
      "std        0.004969       0.007594      0.004641       0.007481   0.287664   \n",
      "min       -0.018363      -0.016826     -0.018363      -0.018900  21.000000   \n",
      "25%       -0.002931      -0.005265     -0.003191      -0.004575  22.000000   \n",
      "50%       -0.001067       0.001223     -0.001428      -0.000166  22.000000   \n",
      "75%        0.001984       0.005245      0.001422       0.004609  22.000000   \n",
      "max        0.014136       0.017616      0.007867       0.027661  22.000000   \n",
      "\n",
      "       Day_Of_Week      Month         Year        ATR  Movement_Class  \n",
      "count    78.000000  78.000000    78.000000  78.000000       78.000000  \n",
      "mean      2.435897   7.435897  2024.384615   0.008150        0.961538  \n",
      "std       2.086380   4.948015     0.489653   0.001232        0.763490  \n",
      "min       0.000000   1.000000  2024.000000   0.005150        0.000000  \n",
      "25%       1.000000   1.000000  2024.000000   0.007729        0.000000  \n",
      "50%       2.000000  11.000000  2024.000000   0.008494        1.000000  \n",
      "75%       3.000000  12.000000  2025.000000   0.008896        2.000000  \n",
      "max       6.000000  12.000000  2025.000000   0.010474        2.000000  \n",
      "\n",
      "[8 rows x 29 columns]\n",
      "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'AHMA', 'Leavitt_Projection',\n",
      "       'Leavitt_Convolution', 'LC_Slope', 'LC_Intercept', 'LC_Acceleration',\n",
      "       'Convolution_Probability', 'Returns', 'Returns_T-1', 'Momentum_T-1',\n",
      "       'Returns_T-2', 'Momentum_T-2', 'Returns_T-5', 'Momentum_T-5',\n",
      "       'Returns_T-10', 'Momentum_T-10', 'Returns_T-21', 'Momentum_T-21',\n",
      "       'Hour', 'Day_Of_Week', 'Month', 'Year', 'ATR', 'Movement_Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned.shape)\n",
    "print(df_cleaned.describe())\n",
    "print(df_cleaned.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the last record??\n",
    "\n",
    "- It should be the record that we will be predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>AHMA</th>\n",
       "      <th>Leavitt_Projection</th>\n",
       "      <th>Leavitt_Convolution</th>\n",
       "      <th>LC_Slope</th>\n",
       "      <th>LC_Intercept</th>\n",
       "      <th>...</th>\n",
       "      <th>Returns_T-10</th>\n",
       "      <th>Momentum_T-10</th>\n",
       "      <th>Returns_T-21</th>\n",
       "      <th>Momentum_T-21</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day_Of_Week</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Movement_Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-02-11 22:00:00-05:00</th>\n",
       "      <td>1.03612</td>\n",
       "      <td>1.03858</td>\n",
       "      <td>1.0354</td>\n",
       "      <td>1.03737</td>\n",
       "      <td>55878</td>\n",
       "      <td>1.034488</td>\n",
       "      <td>1.032559</td>\n",
       "      <td>1.032416</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>1.032455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.006326</td>\n",
       "      <td>-0.00512</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Open     High     Low    Close  Volume  \\\n",
       "Date                                                                   \n",
       "2025-02-11 22:00:00-05:00  1.03612  1.03858  1.0354  1.03737   55878   \n",
       "\n",
       "                               AHMA  Leavitt_Projection  Leavitt_Convolution  \\\n",
       "Date                                                                           \n",
       "2025-02-11 22:00:00-05:00  1.034488            1.032559             1.032416   \n",
       "\n",
       "                           LC_Slope  LC_Intercept  ...  Returns_T-10  \\\n",
       "Date                                               ...                 \n",
       "2025-02-11 22:00:00-05:00 -0.000013      1.032455  ...     -0.001026   \n",
       "\n",
       "                           Momentum_T-10  Returns_T-21  Momentum_T-21  Hour  \\\n",
       "Date                                                                          \n",
       "2025-02-11 22:00:00-05:00       0.002232      0.006326       -0.00512    22   \n",
       "\n",
       "                           Day_Of_Week  Month  Year       ATR  Movement_Class  \n",
       "Date                                                                           \n",
       "2025-02-11 22:00:00-05:00            1      2  2025  0.007814               1  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Step 4: Create an instance of out predict pipeline\n",
    "\n",
    "- Do it an crack on\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2025-02-15 04:29:23,544 ] INFO [src.pipeline.predict_pipeline:27] - Loading model and preprocessor.\n",
      "[ 2025-02-15 04:29:23,605 ] INFO [src.pipeline.predict_pipeline:33] - Model and preprocessor loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from src.pipeline.predict_pipeline import PredictPipeline\n",
    "\n",
    "# Initialize the prediction pipeline\n",
    "predict_pipeline = PredictPipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Step 5: Format the records \n",
    "\n",
    "- Lets try a format and predict something.  Just to say we can\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Timestamp('2024-09-23 21:00:00-0500', tz='UTC-05:00'), 1.11108, 1.1181, 1.11035, 1.11797, 89839], [Timestamp('2024-09-24 21:00:00-0500', tz='UTC-05:00'), 1.11797, 1.12142, 1.11216, 1.1133, 92771], [Timestamp('2024-09-25 21:00:00-0500', tz='UTC-05:00'), 1.1133, 1.11894, 1.11258, 1.11766, 106658], [Timestamp('2024-09-26 21:00:00-0500', tz='UTC-05:00'), 1.11766, 1.12031, 1.11248, 1.1164, 118013], [Timestamp('2024-09-29 21:00:00-0500', tz='UTC-05:00'), 1.1164, 1.1209, 1.11137, 1.11348, 110504], [Timestamp('2024-09-30 21:00:00-0500', tz='UTC-05:00'), 1.11348, 1.11442, 1.1046, 1.10678, 128195], [Timestamp('2024-10-01 21:00:00-0500', tz='UTC-05:00'), 1.10678, 1.10829, 1.10327, 1.10452, 103826], [Timestamp('2024-10-02 21:00:00-0500', tz='UTC-05:00'), 1.10452, 1.10496, 1.10084, 1.10298, 113597], [Timestamp('2024-10-03 21:00:00-0500', tz='UTC-05:00'), 1.10298, 1.10396, 1.09514, 1.0975, 145178], [Timestamp('2024-10-06 21:00:00-0500', tz='UTC-05:00'), 1.0975, 1.0987, 1.09542, 1.09748, 145985], [Timestamp('2024-10-07 21:00:00-0500', tz='UTC-05:00'), 1.09748, 1.09973, 1.0961, 1.09807, 136579], [Timestamp('2024-10-08 21:00:00-0500', tz='UTC-05:00'), 1.09807, 1.0981, 1.09362, 1.094, 124069], [Timestamp('2024-10-09 21:00:00-0500', tz='UTC-05:00'), 1.094, 1.09552, 1.09001, 1.0937, 158405], [Timestamp('2024-10-10 21:00:00-0500', tz='UTC-05:00'), 1.0937, 1.09538, 1.09261, 1.0937, 99627], [Timestamp('2024-10-13 21:00:00-0500', tz='UTC-05:00'), 1.0937, 1.0937, 1.08882, 1.09092, 92600], [Timestamp('2024-10-14 21:00:00-0500', tz='UTC-05:00'), 1.09092, 1.09168, 1.08819, 1.08914, 110300], [Timestamp('2024-10-15 21:00:00-0500', tz='UTC-05:00'), 1.08914, 1.09016, 1.08532, 1.08618, 108487], [Timestamp('2024-10-16 21:00:00-0500', tz='UTC-05:00'), 1.08618, 1.08742, 1.08112, 1.08308, 132161], [Timestamp('2024-10-17 21:00:00-0500', tz='UTC-05:00'), 1.08308, 1.08696, 1.08253, 1.08674, 100003], [Timestamp('2024-10-20 21:00:00-0500', tz='UTC-05:00'), 1.08674, 1.08718, 1.0811, 1.08146, 101766], [Timestamp('2024-10-21 21:00:00-0500', tz='UTC-05:00'), 1.08146, 1.0838, 1.07926, 1.07988, 107934], [Timestamp('2024-10-22 21:00:00-0500', tz='UTC-05:00'), 1.07988, 1.08068, 1.07612, 1.07822, 117711], [Timestamp('2024-10-23 21:00:00-0500', tz='UTC-05:00'), 1.07822, 1.08299, 1.07704, 1.08279, 133213], [Timestamp('2024-10-24 21:00:00-0500', tz='UTC-05:00'), 1.08279, 1.08394, 1.0793, 1.07962, 105179], [Timestamp('2024-10-27 21:00:00-0500', tz='UTC-05:00'), 1.07962, 1.08277, 1.07821, 1.08119, 113728], [Timestamp('2024-10-28 21:00:00-0500', tz='UTC-05:00'), 1.08119, 1.08264, 1.0769, 1.08184, 140424], [Timestamp('2024-10-29 21:00:00-0500', tz='UTC-05:00'), 1.08184, 1.08715, 1.0808, 1.08566, 142476], [Timestamp('2024-10-30 21:00:00-0500', tz='UTC-05:00'), 1.08566, 1.08882, 1.08441, 1.08834, 161366], [Timestamp('2024-10-31 21:00:00-0500', tz='UTC-05:00'), 1.08834, 1.09058, 1.08318, 1.08336, 142067], [Timestamp('2024-11-03 22:00:00-0500', tz='UTC-05:00'), 1.08336, 1.09148, 1.08336, 1.08769, 135549], [Timestamp('2024-11-04 22:00:00-0500', tz='UTC-05:00'), 1.08769, 1.09366, 1.08726, 1.09297, 100436], [Timestamp('2024-11-05 22:00:00-0500', tz='UTC-05:00'), 1.09297, 1.09374, 1.06826, 1.0729, 398838], [Timestamp('2024-11-06 22:00:00-0500', tz='UTC-05:00'), 1.0729, 1.08248, 1.07129, 1.08032, 200127], [Timestamp('2024-11-07 22:00:00-0500', tz='UTC-05:00'), 1.08032, 1.0806, 1.06868, 1.07186, 163576], [Timestamp('2024-11-10 22:00:00-0500', tz='UTC-05:00'), 1.07186, 1.0728, 1.06286, 1.0656, 122065], [Timestamp('2024-11-11 22:00:00-0500', tz='UTC-05:00'), 1.0656, 1.06632, 1.0595, 1.06238, 144282], [Timestamp('2024-11-12 22:00:00-0500', tz='UTC-05:00'), 1.06238, 1.06546, 1.05558, 1.05642, 179758], [Timestamp('2024-11-13 22:00:00-0500', tz='UTC-05:00'), 1.05642, 1.05825, 1.04963, 1.05299, 179321], [Timestamp('2024-11-14 22:00:00-0500', tz='UTC-05:00'), 1.05299, 1.0593, 1.05164, 1.054, 178903], [Timestamp('2024-11-17 22:00:00-0500', tz='UTC-05:00'), 1.054, 1.06072, 1.05304, 1.05985, 132842], [Timestamp('2024-11-18 22:00:00-0500', tz='UTC-05:00'), 1.05985, 1.06012, 1.05234, 1.05962, 175797], [Timestamp('2024-11-19 22:00:00-0500', tz='UTC-05:00'), 1.05962, 1.06098, 1.05068, 1.05436, 132463], [Timestamp('2024-11-20 22:00:00-0500', tz='UTC-05:00'), 1.05436, 1.0555, 1.04622, 1.04746, 151634], [Timestamp('2024-11-21 22:00:00-0500', tz='UTC-05:00'), 1.04746, 1.04981, 1.03319, 1.04186, 197952], [Timestamp('2024-11-24 22:00:00-0500', tz='UTC-05:00'), 1.04186, 1.05304, 1.04186, 1.04966, 182192], [Timestamp('2024-11-25 22:00:00-0500', tz='UTC-05:00'), 1.04966, 1.05448, 1.0425, 1.04894, 211047], [Timestamp('2024-11-26 22:00:00-0500', tz='UTC-05:00'), 1.04894, 1.05877, 1.04744, 1.05667, 184878], [Timestamp('2024-11-27 22:00:00-0500', tz='UTC-05:00'), 1.05667, 1.05698, 1.05275, 1.0555, 118021], [Timestamp('2024-11-28 22:00:00-0500', tz='UTC-05:00'), 1.0555, 1.05973, 1.05414, 1.05778, 188061], [Timestamp('2024-12-01 22:00:00-0500', tz='UTC-05:00'), 1.05778, 1.05778, 1.04606, 1.04989, 224046], [Timestamp('2024-12-02 22:00:00-0500', tz='UTC-05:00'), 1.04989, 1.05351, 1.04806, 1.05097, 163342], [Timestamp('2024-12-03 22:00:00-0500', tz='UTC-05:00'), 1.05097, 1.05442, 1.04723, 1.05102, 183357], [Timestamp('2024-12-04 22:00:00-0500', tz='UTC-05:00'), 1.05102, 1.05897, 1.0508, 1.05877, 144456], [Timestamp('2024-12-05 22:00:00-0500', tz='UTC-05:00'), 1.05877, 1.063, 1.05424, 1.05673, 156813], [Timestamp('2024-12-08 22:00:00-0500', tz='UTC-05:00'), 1.05673, 1.05944, 1.05322, 1.05538, 127133], [Timestamp('2024-12-09 22:00:00-0500', tz='UTC-05:00'), 1.05538, 1.05683, 1.04985, 1.05276, 128726], [Timestamp('2024-12-10 22:00:00-0500', tz='UTC-05:00'), 1.05276, 1.05394, 1.04802, 1.0496, 167050], [Timestamp('2024-12-11 22:00:00-0500', tz='UTC-05:00'), 1.0496, 1.0531, 1.04638, 1.04666, 177799], [Timestamp('2024-12-12 22:00:00-0500', tz='UTC-05:00'), 1.04666, 1.05243, 1.04532, 1.05025, 138932], [Timestamp('2024-12-15 22:00:00-0500', tz='UTC-05:00'), 1.05025, 1.05248, 1.04746, 1.05108, 132411], [Timestamp('2024-12-16 22:00:00-0500', tz='UTC-05:00'), 1.05108, 1.05344, 1.04792, 1.04916, 135615], [Timestamp('2024-12-17 22:00:00-0500', tz='UTC-05:00'), 1.04916, 1.05129, 1.03439, 1.03497, 173985], [Timestamp('2024-12-18 22:00:00-0500', tz='UTC-05:00'), 1.03497, 1.04224, 1.03475, 1.03634, 199843], [Timestamp('2024-12-19 22:00:00-0500', tz='UTC-05:00'), 1.03634, 1.04476, 1.0343, 1.04294, 173942], [Timestamp('2024-12-22 22:00:00-0500', tz='UTC-05:00'), 1.04294, 1.04462, 1.03843, 1.04064, 109526], [Timestamp('2024-12-23 22:00:00-0500', tz='UTC-05:00'), 1.04064, 1.04106, 1.03836, 1.03966, 75060], [Timestamp('2024-12-25 22:00:00-0500', tz='UTC-05:00'), 1.03966, 1.043, 1.03906, 1.04228, 83347], [Timestamp('2024-12-26 22:00:00-0500', tz='UTC-05:00'), 1.04228, 1.04441, 1.04052, 1.04266, 94367], [Timestamp('2024-12-29 22:00:00-0500', tz='UTC-05:00'), 1.04266, 1.04584, 1.03718, 1.04068, 113857], [Timestamp('2024-12-30 22:00:00-0500', tz='UTC-05:00'), 1.04068, 1.04245, 1.03439, 1.03533, 122010], [Timestamp('2025-01-01 22:00:00-0500', tz='UTC-05:00'), 1.03533, 1.03759, 1.02241, 1.0267, 162990], [Timestamp('2025-01-02 22:00:00-0500', tz='UTC-05:00'), 1.0267, 1.031, 1.026, 1.0309, 115944], [Timestamp('2025-01-05 22:00:00-0500', tz='UTC-05:00'), 1.0309, 1.0437, 1.02956, 1.03901, 199453], [Timestamp('2025-01-06 22:00:00-0500', tz='UTC-05:00'), 1.03901, 1.04345, 1.03396, 1.03404, 159695], [Timestamp('2025-01-07 22:00:00-0500', tz='UTC-05:00'), 1.03404, 1.03577, 1.02732, 1.03188, 168443], [Timestamp('2025-01-08 22:00:00-0500', tz='UTC-05:00'), 1.03188, 1.03216, 1.02836, 1.02998, 109898], [Timestamp('2025-01-09 22:00:00-0500', tz='UTC-05:00'), 1.02998, 1.0312, 1.02128, 1.02442, 178804], [Timestamp('2025-01-12 22:00:00-0500', tz='UTC-05:00'), 1.02442, 1.02501, 1.01779, 1.02434, 162314], [Timestamp('2025-01-13 22:00:00-0500', tz='UTC-05:00'), 1.02434, 1.03086, 1.02385, 1.03082, 171360], [Timestamp('2025-01-14 22:00:00-0500', tz='UTC-05:00'), 1.03082, 1.03548, 1.02583, 1.02904, 155515], [Timestamp('2025-01-15 22:00:00-0500', tz='UTC-05:00'), 1.02904, 1.03152, 1.02608, 1.0302, 160175], [Timestamp('2025-01-16 22:00:00-0500', tz='UTC-05:00'), 1.0302, 1.03308, 1.02653, 1.02718, 141219], [Timestamp('2025-01-19 22:00:00-0500', tz='UTC-05:00'), 1.02718, 1.04345, 1.02664, 1.0417, 187472], [Timestamp('2025-01-20 22:00:00-0500', tz='UTC-05:00'), 1.0417, 1.04356, 1.03417, 1.0429, 214932], [Timestamp('2025-01-21 22:00:00-0500', tz='UTC-05:00'), 1.0429, 1.04574, 1.03922, 1.04102, 148134], [Timestamp('2025-01-22 22:00:00-0500', tz='UTC-05:00'), 1.04102, 1.0438, 1.03721, 1.04156, 165378], [Timestamp('2025-01-23 22:00:00-0500', tz='UTC-05:00'), 1.04156, 1.05215, 1.04116, 1.04953, 174843], [Timestamp('2025-01-26 22:00:00-0500', tz='UTC-05:00'), 1.04953, 1.05333, 1.04539, 1.04921, 178570], [Timestamp('2025-01-27 22:00:00-0500', tz='UTC-05:00'), 1.04921, 1.0494, 1.04138, 1.04307, 166715], [Timestamp('2025-01-28 22:00:00-0500', tz='UTC-05:00'), 1.04307, 1.04438, 1.03824, 1.042, 173910], [Timestamp('2025-01-29 22:00:00-0500', tz='UTC-05:00'), 1.042, 1.04678, 1.03862, 1.03923, 169642], [Timestamp('2025-01-30 22:00:00-0500', tz='UTC-05:00'), 1.03923, 1.0434, 1.035, 1.03606, 217371], [Timestamp('2025-02-02 22:00:00-0500', tz='UTC-05:00'), 1.03606, 1.03606, 1.02105, 1.03428, 332786], [Timestamp('2025-02-03 22:00:00-0500', tz='UTC-05:00'), 1.03428, 1.03877, 1.02719, 1.03788, 178263], [Timestamp('2025-02-04 22:00:00-0500', tz='UTC-05:00'), 1.03788, 1.04432, 1.03696, 1.04028, 156914], [Timestamp('2025-02-05 22:00:00-0500', tz='UTC-05:00'), 1.04028, 1.0406, 1.03526, 1.0383, 136702], [Timestamp('2025-02-06 22:00:00-0500', tz='UTC-05:00'), 1.0383, 1.04134, 1.03052, 1.0327, 183108], [Timestamp('2025-02-09 22:00:00-0500', tz='UTC-05:00'), 1.0327, 1.03366, 1.02838, 1.0307, 112919], [Timestamp('2025-02-10 22:00:00-0500', tz='UTC-05:00'), 1.0307, 1.03816, 1.02922, 1.03612, 119270], [Timestamp('2025-02-11 22:00:00-0500', tz='UTC-05:00'), 1.03612, 1.03858, 1.0354, 1.03737, 55878]]\n"
     ]
    }
   ],
   "source": [
    "dohlcv_list = df_dohlcv.values.tolist()\n",
    "print(dohlcv_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Step 6: Format into a DataFrame DOHLCV\n",
    "\n",
    "- Preprocessing happens before entering the pipeline (data is already DOHLCV).\n",
    "- The pipeline focuses only on feature computation, scaling, and inference.\n",
    "- No redundant checks inside the pipeline, leading to faster and more efficient predictions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = validate_ohlcv_batch(dohlcv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(dohlcv_list) < 100:\n",
    "    raise ValueError(\n",
    "        \"Insufficient data: At least 100 records are required for prediction.\"\n",
    "    )\n",
    "\n",
    "# Define column names\n",
    "columns = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "\n",
    "# Convert list to DataFrame\n",
    "df_dohlcv = pd.DataFrame(dohlcv_list, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2025-02-15 04:29:23,617 ] INFO [src.pipeline.predict_pipeline:49] - Starting prediction.\n",
      "[ 2025-02-15 04:29:23,617 ] INFO [src.pipeline.predict_pipeline:51] - Computing necessary features.\n",
      "[ 2025-02-15 04:29:23,618 ] INFO [src.services.data_ingestion_service:67] - Dropped bid and ask price columns.\n",
      "[ 2025-02-15 04:29:23,618 ] INFO [src.services.data_ingestion_service:80] - Renamed mid-price columns to OHLC format.\n",
      "[ 2025-02-15 04:29:23,619 ] INFO [src.services.data_ingestion_service:93] - Set index to Date with unique timestamps.\n",
      "[ 2025-02-15 04:29:23,620 ] INFO [src.services.data_ingestion_service:95] - Processing leavitt data.\n",
      "[ 2025-02-15 04:29:23,629 ] INFO [src.services.data_ingestion_service:97] - Finished leavitt data.\n",
      "[ 2025-02-15 04:29:23,630 ] INFO [src.services.data_ingestion_service:99] - Processing indicators.\n",
      "[ 2025-02-15 04:29:23,632 ] INFO [src.services.data_ingestion_service:101] - Finished indicators.\n",
      "[ 2025-02-15 04:29:23,632 ] INFO [src.services.data_ingestion_service:103] - Processing target.\n",
      "[ 2025-02-15 04:29:23,634 ] INFO [src.services.data_ingestion_service:105] - Finished target.\n",
      "[ 2025-02-15 04:29:23,635 ] INFO [src.services.data_ingestion_service:112] - Dropped NaNs from all columns except Target_T+* fields.\n",
      "[ 2025-02-15 04:29:23,636 ] INFO [src.services.data_ingestion_service:117] - [Data Preprocessing] Input Data Shape: (78, 29)\n",
      "[ 2025-02-15 04:29:23,637 ] INFO [src.services.data_ingestion_service:118] - [Data Preprocessing] Checking for NaNs: 0 NaNs found\n",
      "[ 2025-02-15 04:29:23,640 ] INFO [src.pipeline.predict_pipeline:56] - Data transformed successfully.\n",
      "[ 2025-02-15 04:29:23,643 ] INFO [src.pipeline.predict_pipeline:60] - Prediction completed successfully.\n",
      "(78,) (78,)\n"
     ]
    }
   ],
   "source": [
    "# Now lets predict \n",
    "result = predict_pipeline.predict(df_dohlcv)\n",
    "print(result.predictions.shape, result.confidence.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Step 7: Append the resuls\n",
    "\n",
    "- Get the prediction counts\n",
    "- Convert the named tuple results to a dataframe\n",
    "- Concat the two together\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The number of predictions will be less than the number of records passed in because of the windowing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  vs  78\n"
     ]
    }
   ],
   "source": [
    "prediction_count = result.predictions.shape[0]\n",
    "print(df_dohlcv.shape[0], \" vs \", prediction_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the last N rows from df_lookback where N = number of predictions\n",
    "df_dohlcv_subset = df_dohlcv.tail(prediction_count).reset_index(drop=True)\n",
    "# Convert namedtuple to DataFrame\n",
    "df_predictions = pd.DataFrame(result._asdict())  \n",
    "# Merge datasets\n",
    "df_dohlcv_subset = pd.concat([df_dohlcv_subset, df_predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>predictions</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2025-02-05 22:00:00-05:00</td>\n",
       "      <td>1.04028</td>\n",
       "      <td>1.04060</td>\n",
       "      <td>1.03526</td>\n",
       "      <td>1.03830</td>\n",
       "      <td>136702</td>\n",
       "      <td>0</td>\n",
       "      <td>0.580402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2025-02-06 22:00:00-05:00</td>\n",
       "      <td>1.03830</td>\n",
       "      <td>1.04134</td>\n",
       "      <td>1.03052</td>\n",
       "      <td>1.03270</td>\n",
       "      <td>183108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2025-02-09 22:00:00-05:00</td>\n",
       "      <td>1.03270</td>\n",
       "      <td>1.03366</td>\n",
       "      <td>1.02838</td>\n",
       "      <td>1.03070</td>\n",
       "      <td>112919</td>\n",
       "      <td>1</td>\n",
       "      <td>0.603804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2025-02-10 22:00:00-05:00</td>\n",
       "      <td>1.03070</td>\n",
       "      <td>1.03816</td>\n",
       "      <td>1.02922</td>\n",
       "      <td>1.03612</td>\n",
       "      <td>119270</td>\n",
       "      <td>2</td>\n",
       "      <td>0.910548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2025-02-11 22:00:00-05:00</td>\n",
       "      <td>1.03612</td>\n",
       "      <td>1.03858</td>\n",
       "      <td>1.03540</td>\n",
       "      <td>1.03737</td>\n",
       "      <td>55878</td>\n",
       "      <td>1</td>\n",
       "      <td>0.739840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date     Open     High      Low    Close  Volume  \\\n",
       "73 2025-02-05 22:00:00-05:00  1.04028  1.04060  1.03526  1.03830  136702   \n",
       "74 2025-02-06 22:00:00-05:00  1.03830  1.04134  1.03052  1.03270  183108   \n",
       "75 2025-02-09 22:00:00-05:00  1.03270  1.03366  1.02838  1.03070  112919   \n",
       "76 2025-02-10 22:00:00-05:00  1.03070  1.03816  1.02922  1.03612  119270   \n",
       "77 2025-02-11 22:00:00-05:00  1.03612  1.03858  1.03540  1.03737   55878   \n",
       "\n",
       "    predictions  confidence  \n",
       "73            0    0.580402  \n",
       "74            0    0.947176  \n",
       "75            1    0.603804  \n",
       "76            2    0.910548  \n",
       "77            1    0.739840  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dohlcv_subset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ File saved successfully.\n"
     ]
    }
   ],
   "source": [
    "df_dohlcv_subset.to_csv(\"../data/dohlcv_with_results.csv\", index=False)\n",
    "print(\"‚úÖ File saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
