models:
  Random Forest:
    type: RandomForestClassifier
    params:
      n_estimators: [8, 16, 32, 64, 128, 256]
      max_depth: [3, 5, 7, 10]
      criterion: ["gini", "entropy"]

  Decision Tree:
    type: DecisionTreeClassifier
    params:
      criterion: ["gini", "entropy"]
      max_depth: [3, 5, 7, 10]

  Gradient Boosting:
    type: GradientBoostingClassifier
    params:
      learning_rate: [0.1, 0.01, 0.05, 0.001]
      subsample: [0.6, 0.7, 0.75, 0.8, 0.85, 0.9]
      n_estimators: [8, 16, 32, 64, 128, 256]

  Logistic Regression:
    type: LogisticRegression
    params:
      solver: ["lbfgs", "liblinear"]
      max_iter: [100, 500, 1000]

  XGBClassifier:
    type: XGBClassifier
    params:
      learning_rate: [0.1, 0.01, 0.05, 0.001]
      n_estimators: [8, 16, 32, 64, 128, 256]
      max_depth: [3, 5, 7]
      subsample: [0.8, 1.0]
      colsample_bytree: [0.8, 1.0]
      objective: ["multi:softmax"]
      num_class: [3]

  CatBoostClassifier:
    type: CatBoostClassifier
    verbose: False
    constructor_params:  
      loss_function: MultiClass
      logging_level : Info      #Verbose
      train_dir: artifacts/logs/catboost_training
    params:
      depth: [6, 8]  # ✅ Reduce depth to avoid overfitting
      learning_rate: [0.01, 0.05]  # ✅ Slightly lower learning rate
      iterations: [300, 500]  # ✅ Increase boosting rounds for better generalization
      l2_leaf_reg: [7, 10, 15]  # ✅ Stronger regularization to prevent memorization

  LightGBM:
    type: LGBMClassifier
    constructor_params:
      objective: multiclass  
      verbose: -1 
      force_col_wise: True
    params:
      num_leaves: [15, 31]  # ✅ Reduce complexity for small datasets
      learning_rate: [0.05, 0.1]  # ✅ Prevent slow learning
      n_estimators: [100, 200]  # ✅ More boosting rounds
      max_depth: [4, 5, 6]  # ✅ Force more tree depth
      min_gain_to_split: [0.0001, 0.001]  # ✅ Allow small gain splits
      min_data_in_leaf: [5, 10, 20]  # ✅ Reduce minimum samples per leaf


  AdaBoostClassifier:
    type: AdaBoostClassifier
    params:
      learning_rate: [0.1, 0.01, 0.5, 0.001]
      n_estimators: [8, 16, 32, 64, 128, 256]
